{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing my WordVec-RNN text generator\n",
    "\n",
    "In this notebook I am using the code from NLP Week 8 to test the RNN to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load word vectors***\n",
    "Loading in the word vectors and using the GloVe package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = vocab.GloVe(name=\"6B\",dim=100) \n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "wordvec_embeddings = nn.Embedding.from_pretrained(word_vectors.vectors)\n",
    "embedding_dim = wordvec_embeddings.weight.shape[1]\n",
    "\n",
    "# Get dictionaries from word_vectors class and \n",
    "# rename to be consistent with previous notebooks\n",
    "word_to_ix = word_vectors.stoi\n",
    "ix_to_word = word_vectors.itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Setting the hyperparameters ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100   # size of hidden state\n",
    "num_layers = 3      # number of layers in LSTM layer stack\n",
    "gen_seq_len = 100   # length of LSTM sequence\n",
    "temperature = 10     # how random do we want our predictions to be\n",
    "load_path = \"/Users/loiskelly/Documents/GitHub/LoisNLPProject/Data - NEW/Beatles Word Vector RNN model 3.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Defining the network*** \n",
    "\n",
    "Defining the network with the same code as the training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, input, hidden_state):\n",
    "        output, hidden_state = self.rnn(input, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        output = self.tanh(output)\n",
    "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Setting up network and optimiser:***\n",
    "\n",
    "This is from the note books: \n",
    "\n",
    "[PyTorch tensors](https://pytorch.org/docs/stable/tensors.html) have been designed to work in almost exactly the same way as [numpy arrays](https://numpy.org/doc/stable/reference/generated/numpy.array.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "# Calculate vocab size\n",
    "vocab_size = len(word_to_ix)\n",
    "\n",
    "# Instantiate RNN\n",
    "rnn = RNN(embedding_dim, embedding_dim, hidden_size, num_layers).to(device)\n",
    "\n",
    "# Load model weights from checkpoint file \n",
    "rnn.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generating a random sequence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,860 tohoshinki shoveler sendo un/cefact 18km a-mei rubberneck broadsides -2.9 cheerleading 2,648 gurnee non-scripta nto i-aa federales evaristti amenábar kucherenko shashthi tenes emelia isshu vironia rohul mehdawi ,25 cigar-smoking córas denjū 1,232 mobikom spinalis abogado ørn makmur naghi setesdal huaraches cherryville 95.25 gerak transhumanism termit chicago-based sll bentalha mfecane 43.73 cappio self-reporting chatte ćirić ichilov 2:58 zhiwu mbango appreciator tungning höyük saltair ronalds argentinas cantieri senftenberg dius beevi burmantofts socata ghostscript antoniychuk mabunda coltish .0217 shujah reppy genetech crevier loathes resham trem milanese bandić datel vibrator feest aonghus sharpnose grrrl delicti construido biehler jorvorskie advincula flechette horler betws-y-coed tubize meretskov "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hidden_state = None\n",
    "    \n",
    "    random_word = random.choice(list(ix_to_word))\n",
    "    #Pick a random starting word\n",
    "    random_start = np.array(word_vectors[random_word])\n",
    "    \n",
    "    # Convert to PyTorch Tensor\n",
    "    input = torch.tensor(random_start)\n",
    "    \n",
    "    # Change dimensionality of tensor for PyTorch compatibility\n",
    "    # For more info on this function see: https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch\n",
    "    input = input.unsqueeze(0)\n",
    "    print(input.shape)\n",
    "    # Iterate over our sequence length\n",
    "    for i in range(gen_seq_len):\n",
    "        # Forward pass\n",
    "            output, hidden_state = rnn(input, hidden_state)\n",
    "\n",
    "            # Comput distances to all words\n",
    "            dists = torch.norm(word_vectors.vectors - output[0], dim=1) \n",
    "            # Use softmax to convert to probabilities\n",
    "            probs = F.softmax(1 - dists, dim=0)\n",
    "            # Multiply probabilities by mask to only sample words from dataset\n",
    "            probs = probs\n",
    "            # Covert probabilities to probability distribution\n",
    "            prob_dist = Categorical(probs)\n",
    "            # Sample from probability distribution\n",
    "            word_index  = prob_dist.sample()\n",
    "\n",
    "            # Get the next word and print\n",
    "            next_word = ix_to_word[word_index]\n",
    "            print(next_word, end=' ')\n",
    "            \n",
    "            # The word vector for the next word is the next input\n",
    "            input = word_vectors[next_word].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mapping string to indexes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_str_to_wordvec(input_str):\n",
    "    wordvec_seq = []\n",
    "    tokens = tokenizer(input_str) \n",
    "    for word in tokens:\n",
    "        ix = word_to_ix.get(word, None)\n",
    "        if ix is not None:\n",
    "            wordvec_seq.append(word_vectors[word])\n",
    "        else:\n",
    "            print(f'The char {word} is not in the dictionary')\n",
    "    # Convert list of tensors to one tensor\n",
    "    return torch.stack(wordvec_seq).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the index list and converting it to a numpy array.\n",
    "Here is where I came back and updated the input string for each test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our sequence of word_vecs is: torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "input_str = 'Whisper words'\n",
    "wordvec_seq = map_str_to_wordvec(input_str)\n",
    "print(f'Our sequence of word_vecs is: {wordvec_seq.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generate from randomly created starting sequence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper words "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( three was year but which : in when its he which three after said could - said ; it if by were than over by which ; other said ' some ) her said year last n't other . will said than up $ first had first at ' year as it its but president and : we : _ can other also a over their a and government their are but ( two or state not but only only \" \" - world of were on be world its they be who out other world not last and "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hidden_state = None\n",
    "\n",
    "    print(input_str, end=' ')\n",
    "    for i in range(wordvec_seq.shape[0]):\n",
    "                \n",
    "        # Convert to PyTorch Tensor\n",
    "        input = wordvec_seq[i,:]\n",
    "\n",
    "        # Reshape tensor\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        # Condition the model on starting sequence\n",
    "        output, hidden_state = rnn(input, hidden_state)\n",
    "        \n",
    "    input = output\n",
    "\n",
    "    # Iterate over our sequence length\n",
    "    for i in range(gen_seq_len):\n",
    "        # Forward pass\n",
    "        output, hidden_state = rnn(input, hidden_state)\n",
    "        \n",
    "        # Construct categorical distribution and sample a word\n",
    "        output = F.softmax(torch.squeeze(output), dim=0)\n",
    "        dist = Categorical(output / temperature)\n",
    "        index = dist.sample()\n",
    "        \n",
    "        # Print the sampled word\n",
    "        print(ix_to_word[index.item()], end=' ')\n",
    "        \n",
    "        # Next input is current output\n",
    "        input[0][0] = index.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
