{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a text generator with Word-RNN \n",
    "\n",
    "In this notebook I am using the code from NLP Week 7 to train my RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the hyperparameters:**\n",
    "\n",
    "Whilst working with this notebook I was going back to the below cell to change the Hidden State Size and Number of layers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512   # size of hidden state\n",
    "num_layers = 3      # number of layers in LSTM layer stack\n",
    "gen_seq_len = 100   # length of LSTM sequence\n",
    "temperature = 10    # how random do we want our predictions to be\n",
    "load_path = \"/Users/loiskelly/Documents/GitHub/LoisNLPProject/all_data/Beatles Word RNN Model 5.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Defining the network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_batch, hidden_state):\n",
    "        embedding = self.embedding(input_batch)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Setting up network and optimiser:***\n",
    "\n",
    "This is from the note books: \n",
    "\n",
    "[PyTorch tensors](https://pytorch.org/docs/stable/tensors.html) have been designed to work in almost exactly the same way as [numpy arrays](https://numpy.org/doc/stable/reference/generated/numpy.array.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "# Load word_to_ix and ix_to_word dictionaries from checkpoint file\n",
    "word_to_ix = checkpoint['word_to_ix']\n",
    "ix_to_word = checkpoint['ix_to_word']\n",
    "\n",
    "# Calculate vocab size\n",
    "vocab_size = len(word_to_ix)\n",
    "\n",
    "# Instantiate RNN\n",
    "rnn = RNN(vocab_size, vocab_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "# Load model weights from checkpoint file \n",
    "rnn.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a random sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of all comes Well I feel happy "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just it did you girl you hurt me if you know how hard to understand cause Its been unhappy and hoping Im changing it up your feet back home things in love never be alright? Alright? Alright? You better The girl Here there It feels like Ive waited only goes on your head Bang bang Maxwells silver hammer Came very long Please dont know my own mind I could be sad just of ten its all I said move over Beethoven Roll over Even throws it calls me oh yeh Imagine Im with "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hidden_state = None\n",
    "    \n",
    "    #Pick a random starting word\n",
    "    random_start = np.array(random.choice(list(word_to_ix.values())))\n",
    "    \n",
    "    # Convert to PyTorch Tensor\n",
    "    input_seq = torch.tensor(random_start, dtype=torch.int64)\n",
    "    \n",
    "    # Change dimensionality of tensor for PyTorch compatibility\n",
    "    # For more info on this function see: https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch\n",
    "    input_seq = input_seq.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Iterate over our sequence length\n",
    "    for i in range(gen_seq_len):\n",
    "        # Forward pass\n",
    "        output, hidden_state = rnn(input_seq, hidden_state)\n",
    "        \n",
    "        # Construct categorical distribution and sample a word\n",
    "        output = F.softmax(torch.squeeze(output), dim=0)\n",
    "        dist = Categorical(output / temperature)\n",
    "        index = dist.sample()\n",
    "        \n",
    "        # Print the sampled word\n",
    "        print(ix_to_word[index.item()], end=' ')\n",
    "        \n",
    "        # Next input is current output\n",
    "        input_seq[0][0] = index.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Map string to indexes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_str_to_ix(input_str):\n",
    "    index_list = []\n",
    "    for word in input_str.split():\n",
    "        ix = word_to_ix.get(word, None)\n",
    "        if ix is not None:\n",
    "            index_list.append(ix)\n",
    "        else:\n",
    "            print(f'The word {word} is not in the dictionary')\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the index list and converting it to a numpy array.\n",
    "Here is where I came back and updated the input string for each test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our list is: [984, 2158, 3582]\n"
     ]
    }
   ],
   "source": [
    "input_str = 'Why hello there'\n",
    "index_list = map_str_to_ix(input_str)\n",
    "print(f'Our list is: {index_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generate from randomly created starting sequence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why hello there To become energy wearing rings it easy You wont see shell matter what you too much Though the single reason When you do me do they all together dressed in the same if you dont care Theres nothing to dance with a hard it on baby Yeeeeh baby you Shell remember just look at all belong? All thru this world around you evry fool and friends and that when I want her She like me â€˜Cause I even listen to pretend But till your own girl You tell you can talk to lose affection known high Newspaper taxis appear to "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hidden_state = None\n",
    "\n",
    "    for ix in index_list:\n",
    "        \n",
    "        # Print current input sequence\n",
    "        print(ix_to_word[ix], end=' ')\n",
    "\n",
    "        #Pick a random starting word\n",
    "        current_ix = np.array(ix)\n",
    "        \n",
    "        # Convert to PyTorch Tensor\n",
    "        input = torch.tensor(current_ix, dtype=torch.int64)\n",
    "        \n",
    "        # Change dimensionality of tensor for PyTorch compatibility\n",
    "        # For more info on this function see: https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch\n",
    "        input = input.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # Condition the model on starting sequence\n",
    "        output, hidden_state = rnn(input, hidden_state)\n",
    "\n",
    "\n",
    "    # Iterate over our sequence length\n",
    "    for i in range(gen_seq_len):\n",
    "        # Forward pass\n",
    "        output, hidden_state = rnn(input, hidden_state)\n",
    "        \n",
    "        # Construct categorical distribution and sample a word\n",
    "        output = F.softmax(torch.squeeze(output), dim=0)\n",
    "        dist = Categorical(output / temperature)\n",
    "        index = dist.sample()\n",
    "        \n",
    "        # Print the sampled word\n",
    "        print(ix_to_word[index.item()], end=' ')\n",
    "        \n",
    "        # Next input is current output\n",
    "        input[0][0] = index.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
